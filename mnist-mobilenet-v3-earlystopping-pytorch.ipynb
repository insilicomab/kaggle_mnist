{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fogdiffusion/mnist-mobilenet-v3-earlystopping-pytorch?scriptVersionId=91897681\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-02T02:12:12.42521Z","iopub.execute_input":"2022-04-02T02:12:12.425978Z","iopub.status.idle":"2022-04-02T02:12:12.45403Z","shell.execute_reply.started":"2022-04-02T02:12:12.425867Z","shell.execute_reply":"2022-04-02T02:12:12.453343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import package\nimport os\nimport random\nfrom glob import glob\nfrom warnings import filterwarnings\n\nimport argparse\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\n\nfrom collections import defaultdict\n\nfilterwarnings('ignore') ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:12.585668Z","iopub.execute_input":"2022-04-02T02:12:12.585871Z","iopub.status.idle":"2022-04-02T02:12:15.379689Z","shell.execute_reply.started":"2022-04-02T02:12:12.585847Z","shell.execute_reply":"2022-04-02T02:12:15.378782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random seed\ntorch.manual_seed(1234)\ntorch.cuda.manual_seed(1234)\nnp.random.seed(1234)\nrandom.seed(1234)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:15.384105Z","iopub.execute_input":"2022-04-02T02:12:15.38436Z","iopub.status.idle":"2022-04-02T02:12:15.395496Z","shell.execute_reply.started":"2022-04-02T02:12:15.384327Z","shell.execute_reply":"2022-04-02T02:12:15.394647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gpu or cpu\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nkwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {} \nprint(f'device：{device}')","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:15.399848Z","iopub.execute_input":"2022-04-02T02:12:15.400326Z","iopub.status.idle":"2022-04-02T02:12:15.4594Z","shell.execute_reply.started":"2022-04-02T02:12:15.400285Z","shell.execute_reply":"2022-04-02T02:12:15.458629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set constant\npretrained = True\n\n# Model name\nmodel_name = 'mobilenet_v3_large'","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:15.461553Z","iopub.execute_input":"2022-04-02T02:12:15.461913Z","iopub.status.idle":"2022-04-02T02:12:15.467417Z","shell.execute_reply.started":"2022-04-02T02:12:15.461875Z","shell.execute_reply":"2022-04-02T02:12:15.466734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter\nparser = argparse.ArgumentParser()\nparser.add_argument('--test_size', type=float, default=0.3)\nparser.add_argument('--image_size', type=int, default=28)\nparser.add_argument('--num_classes', type=int, default=10)\nparser.add_argument('--epochs', type=int, default=100)\nparser.add_argument('--batch_size', type=int, default=16)\nparser.add_argument('--lr', type=float, default=1e-4) # learning rate\nparser.add_argument('--patience', type=int, default=10) # earlystopping monitoring times\nopt = parser.parse_args(args=[])\nprint(opt)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:15.468823Z","iopub.execute_input":"2022-04-02T02:12:15.469074Z","iopub.status.idle":"2022-04-02T02:12:15.479419Z","shell.execute_reply.started":"2022-04-02T02:12:15.46904Z","shell.execute_reply":"2022-04-02T02:12:15.478651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset, Dataloader","metadata":{}},{"cell_type":"code","source":"# read data\ntrain_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\nprint(train_df.head())\nprint('number of data: ', train_df.shape[0])\n\n# split into train and validation data\ntrain, val = train_test_split(train_df, test_size=opt.test_size, random_state=42, stratify=train_df['label'])\nprint(train.head())\nprint('number of train: ', train.shape[0])\nprint('number of val: ', val.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:15.480653Z","iopub.execute_input":"2022-04-02T02:12:15.480964Z","iopub.status.idle":"2022-04-02T02:12:18.985223Z","shell.execute_reply.started":"2022-04-02T02:12:15.480928Z","shell.execute_reply":"2022-04-02T02:12:18.984511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform\ntransform = {\n    'train': transforms.Compose([\n        transforms.ToPILImage(),\n        #transforms.RandomRotation(degrees=20),\n        transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n        ]),\n    'val': transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n        ]),\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:18.986438Z","iopub.execute_input":"2022-04-02T02:12:18.987191Z","iopub.status.idle":"2022-04-02T02:12:18.994134Z","shell.execute_reply.started":"2022-04-02T02:12:18.98715Z","shell.execute_reply":"2022-04-02T02:12:18.993314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass MNISTDataset(Dataset):\n    def __init__(self, df, transform=None, phase=None):\n        self.df = df\n        self.transform = transform\n        self.phase = phase\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        \n        # loads the index-th image and preprocesses it\n        data = self.df.iloc[index]\n        image = data[1:].values.reshape((28,28)).astype(np.uint8)\n        image = self.transform[self.phase](image)\n        \n        # get the index-th label\n        label = data[0]\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:18.995305Z","iopub.execute_input":"2022-04-02T02:12:18.995849Z","iopub.status.idle":"2022-04-02T02:12:19.010682Z","shell.execute_reply.started":"2022-04-02T02:12:18.995818Z","shell.execute_reply":"2022-04-02T02:12:19.009916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiation of Dataset\ntrain_dataset = MNISTDataset(df=train, transform=transform, phase='train')\nval_dataset = MNISTDataset(df=val, transform=transform, phase='val')","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:19.013422Z","iopub.execute_input":"2022-04-02T02:12:19.0141Z","iopub.status.idle":"2022-04-02T02:12:19.020278Z","shell.execute_reply.started":"2022-04-02T02:12:19.014065Z","shell.execute_reply":"2022-04-02T02:12:19.019509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataloader\ndataloader = {\n    'train': DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True),\n    'val': DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False)\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:19.022363Z","iopub.execute_input":"2022-04-02T02:12:19.022548Z","iopub.status.idle":"2022-04-02T02:12:19.031675Z","shell.execute_reply.started":"2022-04-02T02:12:19.022525Z","shell.execute_reply":"2022-04-02T02:12:19.030967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check images\ntrain_iter = iter(dataloader['train'])\nimgs, labels = train_iter.next()\nprint(imgs.size())\nprint(labels)\n\n# display first image\nimg = imgs[0].reshape((28,28))\nplt.imshow(img, cmap='gray')\nprint('ラベル', np.array(labels[0]))","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:19.033044Z","iopub.execute_input":"2022-04-02T02:12:19.033445Z","iopub.status.idle":"2022-04-02T02:12:19.31922Z","shell.execute_reply.started":"2022-04-02T02:12:19.033408Z","shell.execute_reply":"2022-04-02T02:12:19.31855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EarlyStoppling Class","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=10, verbose=0):\n        '''\n        Parameters:\n            patience(int): number of epochs to monitor (default: 10)\n            verbose(int): output flag for early termination\n                          output(1), don't output(0)      \n        '''\n        # initialize instance variables\n        # initialize the counter for the number of epochs being monitored\n        self.epoch = 0\n        # initialize loss for comparison with infinity 'inf'.\n        self.pre_loss = float('inf')\n        # initialize the number of epochs to be monitored with parameters\n        self.patience = patience\n        # initialize the output flag for early termination messages with a parameter\n        self.verbose = verbose\n        \n    def __call__(self, current_loss):\n        '''\n        Parameters:\n            current_loss(float): loss of validation data after 1 epoch\n        Return:\n            True: If the loss of the previous epoch is exceeded by the maximum number of monitoring times\n            False: If the loss of the previous epoch is not exceeded by the maximum number of monitored epochs\n        '''\n        # If the loss is greater than the loss in the previous epoch\n        if self.pre_loss < current_loss:\n            self.epoch += 1 # Counter += 1\n            # When the maximum number of monitoring times is reached\n            if self.epoch > self.patience:\n                if self.verbose: # # If the flag for early termination is 1\n                    print('early stopping')\n                return True # return True to terminate training\n        # If the loss is less than or equal to the loss of the previous epoch\n        else:\n            self.epoch = 0               # counter: 0\n            self.pre_loss = current_loss # update loss values\n        \n        # If the loss of the previous epoch is not exceeded by the maximum number of monitoring times\n        # return False to continue learning\n        # If the loss of the previous epoch is exceeded but within the number of times monitored\n        # note that the return statement is located here because it must return False\n        return False","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:19.320529Z","iopub.execute_input":"2022-04-02T02:12:19.320962Z","iopub.status.idle":"2022-04-02T02:12:19.32936Z","shell.execute_reply.started":"2022-04-02T02:12:19.320923Z","shell.execute_reply":"2022-04-02T02:12:19.328651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = models.mobilenet_v3_large(pretrained=pretrained)\nmodel.features[0][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) # change input channel\nfc_in_features = model.classifier[3].out_features # number of dimensions of the final layer function\nmodel.fc = nn.Linear(fc_in_features, opt.num_classes) # change final layer\nprint(model)\n\n# model to device\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:19.330766Z","iopub.execute_input":"2022-04-02T02:12:19.331066Z","iopub.status.idle":"2022-04-02T02:12:22.625408Z","shell.execute_reply.started":"2022-04-02T02:12:19.331031Z","shell.execute_reply":"2022-04-02T02:12:22.624729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# definition of loss function and optimization function\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=opt.lr)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:22.626692Z","iopub.execute_input":"2022-04-02T02:12:22.627083Z","iopub.status.idle":"2022-04-02T02:12:22.633418Z","shell.execute_reply.started":"2022-04-02T02:12:22.627043Z","shell.execute_reply":"2022-04-02T02:12:22.632603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dict object for storing loss and accuracy history\nhistory = {'train_loss':[],'train_accuracy':[], 'val_loss':[], 'val_accuracy':[]}\n\n# generate an object to determine early termination\ners = EarlyStopping(patience=opt.patience, # monitoring times\n                    verbose=1)  # output meassage when early stopping\n\n\n# define training model\ndef train_model(model, epochs, loss_fn, optimizer):\n    \n    # initialize best score\n    best_loss = np.inf\n    \n    # setting of epoch loop\n    for epoch in range(epochs):\n        \n        # output of number of current epoch\n        print(f'Epoch: {epoch+1} / {epochs}')\n        print('--------------------------')\n        \n         # setting train / val\n        for phase in ['train', 'val']:\n            \n            # change train / val\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            # reset loss\n            epoch_loss = 0.0\n            # number of correct\n            corrects = 0\n            # reset pred-list\n            pred_list = []\n            # reset correct-list\n            true_list = []\n            \n            # reading data from dataloader in mini-batch (batch_size) units\n            for images, labels in dataloader[phase]:\n                \n                # move images and labels to the same device as the model\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                # initialize slope information\n                optimizer.zero_grad()\n                \n                # enable gradient information only when learning\n                with torch.set_grad_enabled(phase=='train'):\n                    \n                    # model calculation\n                    outputs = model(images)\n                    # calculation of loss values\n                    loss = loss_fn(outputs, labels)\n                    # calculation of predictive labels\n                    preds = torch.argmax(outputs, dim=1) # output preds\n                    \n                    # update back-propagation and parameter only during training\n                    if phase == 'train':\n                        \n                        # calculation of gradient by error back propagation method\n                        loss.backward()\n                        # update optimizer\n                        optimizer.step()\n                    \n                    # add loss\n                    epoch_loss += loss.item() * images.size(0)\n                    \n                    # add correct\n                    corrects += torch.sum(preds == labels.data)                    \n                    \n                    # add predicted label to pred-list\n                    preds = preds.to('cpu').numpy()\n                    pred_list.extend(preds)\n                    \n                    # add correct label to true-list\n                    labels = labels.to('cpu').numpy()\n                    true_list.extend(labels)\n            \n            # average of loss values within 1 epoch\n            epoch_loss = epoch_loss / len(dataloader[phase].dataset)\n            \n            # calculation of the percentage of correct answers\n            accuracy = corrects.double() / len(dataloader[phase].dataset)\n            accuracy = accuracy.to('cpu').detach().numpy().copy() # Tensor → Numpy\n            \n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_accuracy'].append(accuracy)\n            \n            # outputs each evaluation score\n            print(f'{phase} Loss: {epoch_loss:.4f} Accuracy: {accuracy:.4f}')\n            \n            # During validation, make a large/small comparison between the validation score and the best score\n            if (phase == 'val') and (epoch_loss < best_loss):\n                \n                ## Only if the validation score improves, do the following\n                \n                # update best score\n                best_loss = epoch_loss\n                # set param name\n                param_name = f'/kaggle/working/{model_name}.pth'\n                # save model\n                torch.save(model, param_name)\n        \n        # pass loss of validation data to EarlyStopping object to determine early termination\n        if (phase == 'val') and ers(epoch_loss):\n            # If losses do not improve at the monitored epoch, learning is terminated\n            break","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:22.634817Z","iopub.execute_input":"2022-04-02T02:12:22.635177Z","iopub.status.idle":"2022-04-02T02:12:22.652895Z","shell.execute_reply.started":"2022-04-02T02:12:22.635139Z","shell.execute_reply":"2022-04-02T02:12:22.652226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\ntrain_model(model, opt.epochs, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T02:12:22.655146Z","iopub.execute_input":"2022-04-02T02:12:22.655345Z","iopub.status.idle":"2022-04-02T02:24:47.949704Z","shell.execute_reply.started":"2022-04-02T02:12:22.655321Z","shell.execute_reply":"2022-04-02T02:24:47.948464Z"},"trusted":true},"execution_count":null,"outputs":[]}]}